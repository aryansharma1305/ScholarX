# ScholarX - Research Paper RAG Pipeline

A production-ready Python RAG pipeline for semantic search and question answering over research papers. Built with ChromaDB, Sentence Transformers, and advanced retrieval techniques.

## ğŸš€ Quick Start

```bash
# Install dependencies
pip install -r requirements.txt

# Set up .env (see .env.example)
cp .env.example .env
# Edit .env with your settings

# Add papers
python3 add_papers.py

# Query interactively
python3 query_interactive.py

# Manage collection
python3 manage_papers.py
```

## ğŸ“ Project Structure

```
python-rag/
â”œâ”€â”€ main.py                    # Core functions
â”œâ”€â”€ add_papers.py              # Add papers (interactive)
â”œâ”€â”€ query_interactive.py       # Query interface (with modes)
â”œâ”€â”€ manage_papers.py           # Collection management
â”œâ”€â”€ view_results.py            # View saved queries
â”œâ”€â”€ scale_example.py           # Large-scale ingestion
â”œâ”€â”€ feature_showcase.py        # Demo all features
â”œâ”€â”€ advanced_features.py       # Advanced features demo
â”œâ”€â”€ api/                       # Feature APIs
â”‚   â”œâ”€â”€ main_api.py           # Unified API interface
â”‚   â”œâ”€â”€ paper_api.py          # Paper details & summaries
â”‚   â”œâ”€â”€ citations.py          # Citation graph
â”‚   â”œâ”€â”€ summaries.py          # Auto-summarization
â”‚   â”œâ”€â”€ authors.py            # Author graph & stats
â”‚   â”œâ”€â”€ topics.py             # Topic clustering
â”‚   â”œâ”€â”€ rag_modes.py          # Advanced RAG modes
â”‚   â”œâ”€â”€ deduplication.py       # Duplicate detection
â”‚   â”œâ”€â”€ similarity.py         # Similarity checking
â”‚   â”œâ”€â”€ ranking.py            # Citation rankings
â”‚   â””â”€â”€ query_logger.py       # Query analytics
â”œâ”€â”€ config/                    # Configuration
â”‚   â”œâ”€â”€ settings.py
â”‚   â”œâ”€â”€ chroma_client.py
â”‚   â””â”€â”€ openai_client.py
â”œâ”€â”€ ingestion/                 # Paper loading
â”‚   â”œâ”€â”€ pdf_loader.py
â”‚   â”œâ”€â”€ paper_fetcher.py
â”‚   â”œâ”€â”€ ingest_pipeline.py
â”‚   â”œâ”€â”€ enhanced_metadata.py
â”‚   â””â”€â”€ text_cleaner.py
â”œâ”€â”€ processing/                # Text processing
â”‚   â”œâ”€â”€ chunker.py
â”‚   â”œâ”€â”€ advanced_chunker.py
â”‚   â””â”€â”€ embeddings.py
â”œâ”€â”€ vectorstore/               # Vector operations
â”‚   â”œâ”€â”€ upsert.py
â”‚   â””â”€â”€ query.py
â”œâ”€â”€ rag/                       # RAG pipeline
â”‚   â”œâ”€â”€ pipeline.py
â”‚   â”œâ”€â”€ retriever.py
â”‚   â”œâ”€â”€ generator.py
â”‚   â”œâ”€â”€ hybrid_search.py
â”‚   â”œâ”€â”€ reranker.py
â”‚   â”œâ”€â”€ quality_scorer.py
â”‚   â”œâ”€â”€ query_expander.py
â”‚   â””â”€â”€ search_enhanced.py
â””â”€â”€ utils/                     # Utilities
    â”œâ”€â”€ logger.py
    â””â”€â”€ timers.py
```

## âœ¨ Features

### Core Features (MVP)
- âœ… **PDF Ingestion**: Load papers from URLs or Semantic Scholar/ArXiv
- âœ… **Semantic Search**: Vector-based similarity search
- âœ… **Metadata Storage**: Title, authors, abstract, year, DOI, etc.
- âœ… **RAG QA**: Question answering with citations

### Good Project Features
- âœ… **Hybrid Search**: Combines semantic + keyword search
- âœ… **Paper API**: Get paper details, summaries, chunks
- âœ… **Citation Graph**: Find related and citing papers
- âœ… **Chunk Provenance**: Track which chunk came from which paper
- âœ… **Query Logging**: Analytics on queries and usage

### Standout Features
- âœ… **Auto Summaries**: Generate short, medium, and bullet-point summaries
- âœ… **Author Graph**: Author statistics, co-author networks, profiles
- âœ… **Topic Clustering**: Organize papers by topics using K-Means
- âœ… **Advanced RAG Modes**: Concise, detailed, explain, compare, literature survey
- âœ… **Multi-Document Synthesis**: Query across multiple specific papers

### Optional Features
- âœ… **Citation Ranking**: Rank papers by citation metrics
- âœ… **Related Papers**: Find similar papers automatically
- âœ… **Deduplication**: Detect and merge duplicate papers
- âœ… **Similarity Checking**: Compare papers or check text similarity
- âœ… **ArXiv Version Normalization**: Handle paper versions

## ğŸ“– Usage

### Add Papers
```bash
python3 add_papers.py
# Option 1: Fetch by topic
# Option 2: Add from PDF URL
```

### Query System
```bash
python3 query_interactive.py
# Ask questions naturally
# Results saved automatically
```

### Manage Collection
```bash
python3 manage_papers.py
# List, delete, export, view stats
```

### Batch Add Many Papers
```bash
python3 scale_example.py
# Pre-configured batch ingestion
```

### Advanced Features Demo
```bash
python3 feature_showcase.py
# See all features in action
```

### Use API Programmatically
```python
from api.main_api import api

# Get paper details
paper = api.get_paper("paper-id")

# Generate summary
summary = api.generate_summary("paper-id")

# Advanced RAG modes
result = api.rag_concise("What is attention?")
result = api.rag_compare("Compare transformer architectures")
result = api.rag_survey("neural machine translation")

# Author analysis
stats = api.get_author_statistics()
profile = api.get_author("John Doe")

# Topic clustering
clusters = api.cluster_topics(num_clusters=5)

# Find duplicates
duplicates = api.find_duplicates()

# Check similarity
similar = api.check_similarity("some text", threshold=0.8)
```

## âš™ï¸ Configuration

Edit `.env`:
```env
EMBEDDING_PROVIDER=sentence-transformers  # Free, local
LLM_PROVIDER=simple                        # Template-based
CHUNK_SIZE=1000
MAX_PAPERS_PER_QUERY=5
```

## ğŸ”§ Requirements

- Python 3.10+
- See `requirements.txt` for dependencies
- No API keys needed for free mode!

## ğŸ“ License

ISC
